from pyspark.sql import SparkSession
from pyspark.sql.types import (
    StringType, DecimalType, IntegerType, StructType, StructField
)

# åˆå§‹åŒ–SparkSessionï¼Œé€‚é…Hiveç¯å¢ƒå¹¶é…ç½®åŠ¨æ€åˆ†åŒº
spark = SparkSession.builder \
    .appName("CreateAdsProductValueEvaluationInGdDB") \
    .config("spark.sql.catalogImplementation", "hive") \
    .config("spark.sql.warehouse.dir", "/user/hive/warehouse") \
    .config("hive.exec.dynamic.partition", "true")   \
    .config("hive.exec.dynamic.partition.mode", "nonstrict")   \
    .enableHiveSupport() \
    .getOrCreate()

# 1. ç¡®ä¿gdæ•°æ®åº“å­˜åœ¨ï¼ˆæ–‡æ¡£ä¸­ADSå±‚æ•°æ®æ‰€å±åº“ï¼‰
spark.sql("CREATE DATABASE IF NOT EXISTS gd COMMENT 'ç”µå•†æ•°ä»“ADSå±‚ï¼Œå­˜å‚¨å•†å“è¯Šæ–­çœ‹æ¿ç›¸å…³æ•°æ®'")

# 2. åœ¨gdåº“ä¸­åˆ›å»ºè¡¨ï¼ˆä¸¥æ ¼åŒ¹é…æ–‡æ¡£å…¨å“ä»·å€¼è¯„ä¼°çš„ADSå±‚è®¾è®¡ï¼‰
create_table_sql = """
CREATE TABLE IF NOT EXISTS gd.ads_product_value_evaluation (
    product_id STRING COMMENT 'å•†å“å”¯ä¸€æ ‡è¯†ID',
    product_name STRING COMMENT 'å•†å“åç§°',
    traffic_acquisition_score DECIMAL(5,2) COMMENT 'æµé‡è·å–ç»´åº¦è¯„åˆ†ï¼ˆç”¨äºç»¼åˆè¯„åˆ†è®¡ç®—ï¼‰',
    traffic_conversion_score DECIMAL(5,2) COMMENT 'æµé‡è½¬åŒ–ç»´åº¦è¯„åˆ†ï¼ˆç”¨äºç»¼åˆè¯„åˆ†è®¡ç®—ï¼‰',
    content_marketing_score DECIMAL(5,2) COMMENT 'å†…å®¹è¥é”€ç»´åº¦è¯„åˆ†ï¼ˆç”¨äºç»¼åˆè¯„åˆ†è®¡ç®—ï¼‰',
    customer_acquisition_score DECIMAL(5,2) COMMENT 'å®¢æˆ·æ‹‰æ–°ç»´åº¦è¯„åˆ†ï¼ˆç”¨äºç»¼åˆè¯„åˆ†è®¡ç®—ï¼‰',
    service_quality_score DECIMAL(5,2) COMMENT 'æœåŠ¡è´¨é‡ç»´åº¦è¯„åˆ†ï¼ˆç”¨äºç»¼åˆè¯„åˆ†è®¡ç®—ï¼‰',
    total_score DECIMAL(5,2) COMMENT 'ç»¼åˆè¯„åˆ†ï¼ˆåŸºäºä¸Šè¿°äº”ç»´åº¦è®¡ç®—ï¼‰',
    level STRING COMMENT 'è¯„åˆ†ç­‰çº§ï¼ˆA/B/C/Dçº§ï¼Œ85åˆ†ä»¥ä¸Šä¸ºAçº§ï¼Œ70-85åˆ†ä¸ºBçº§ï¼Œ50-70åˆ†ä¸ºCçº§ï¼Œ50åˆ†ä»¥ä¸‹ä¸ºDçº§ï¼‰ğŸ”¶1-26ğŸ”¶',
    amount DECIMAL(12,2) COMMENT 'é”€å”®é¢ï¼ˆé‡‘é¢ç»´åº¦ï¼Œæ”¯æ’‘"è¯„åˆ†-é‡‘é¢"åˆ†æï¼‰ğŸ”¶1-20ğŸ”¶',
    price DECIMAL(8,2) COMMENT 'å•ä»·ï¼ˆä»·æ ¼ç»´åº¦ï¼Œæ”¯æ’‘"ä»·æ ¼-é”€é‡"åˆ†æï¼‰ğŸ”¶1-20ğŸ”¶',
    sales_num INT COMMENT 'é”€é‡ï¼ˆæ”¯æ’‘"ä»·æ ¼-é”€é‡"/"è®¿å®¢-é”€é‡"åˆ†æï¼‰ğŸ”¶1-20ğŸ”¶',
    visitor_num INT COMMENT 'è®¿å®¢æ•°ï¼ˆæ”¯æ’‘"è®¿å®¢-é”€é‡"åˆ†æï¼‰ğŸ”¶1-20ğŸ”¶',
    visitor_sales_ratio DECIMAL(5,2) COMMENT 'è®¿å®¢-é”€é‡æ¯”ï¼ˆé”€é‡/è®¿å®¢æ•°ï¼Œè¯„ä¼°è®¿å®¢è½¬åŒ–æ•ˆç‡ï¼‰'
)
PARTITIONED BY (stat_date STRING COMMENT 'ç»Ÿè®¡æ—¥æœŸï¼ŒæŒ‰å¤©åˆ†åŒºå­˜å‚¨')
STORED AS PARQUET
COMMENT 'å…¨å“ä»·å€¼è¯„ä¼°ADSå±‚è¡¨ï¼Œä»»åŠ¡ç¼–å·ï¼šå¤§æ•°æ®-ç”µå•†æ•°ä»“-07-å•†å“ä¸»é¢˜å•†å“è¯Šæ–­çœ‹æ¿ï¼Œç”¨äºå…¨é¢äº†è§£åº—é“ºå•†å“åˆ†å¸ƒï¼Œèšç„¦æ ¸å¿ƒå•†å“å’Œæ½œåŠ›å•†å“ğŸ”¶1-21ğŸ”¶'
"""
spark.sql(create_table_sql)

# 3. è¯»å–CSVæ•°æ®ï¼ˆSchemaä¸è¡¨ç»“æ„ä¸¥æ ¼ä¸€è‡´ï¼‰
csv_path = "ads_product_value_evaluation_10000.csv"  # æ›¿æ¢ä¸ºå®é™…CSVè·¯å¾„
schema = StructType([
    StructField("product_id", StringType(), nullable=False),
    StructField("product_name", StringType(), nullable=True),
    StructField("stat_date", StringType(), nullable=False),  # åˆ†åŒºå­—æ®µ
    StructField("traffic_acquisition_score", DecimalType(5, 2), nullable=True),
    StructField("traffic_conversion_score", DecimalType(5, 2), nullable=True),
    StructField("content_marketing_score", DecimalType(5, 2), nullable=True),
    StructField("customer_acquisition_score", DecimalType(5, 2), nullable=True),
    StructField("service_quality_score", DecimalType(5, 2), nullable=True),
    StructField("total_score", DecimalType(5, 2), nullable=True),
    StructField("level", StringType(), nullable=True),
    StructField("amount", DecimalType(12, 2), nullable=True),
    StructField("price", DecimalType(8, 2), nullable=True),
    StructField("sales_num", IntegerType(), nullable=True),
    StructField("visitor_num", IntegerType(), nullable=True),
    StructField("visitor_sales_ratio", DecimalType(5, 2), nullable=True)
])

df = spark.read \
    .format("csv") \
    .option("header", "true") \
    .schema(schema) \
    .load(csv_path)

# 4. å°†æ•°æ®å†™å…¥gdåº“ä¸­çš„è¡¨ï¼ˆåŠ¨æ€åˆ†åŒºæ¨¡å¼ï¼Œç¬¦åˆæ–‡æ¡£å­˜å‚¨è¦æ±‚ï¼‰
df.write \
    .mode("append") \
    .format("hive")  \
    .partitionBy("stat_date")   \
    .saveAsTable("gd.ads_product_value_evaluation")

# 5. éªŒè¯è¡¨åˆ›å»ºåŠæ•°æ®æ’å…¥ç»“æœ
table_exists = spark.catalog.tableExists("gd.ads_product_value_evaluation")
count = spark.sql("SELECT COUNT(*) FROM gd.ads_product_value_evaluation").collect()[0][0] if table_exists else 0
print(f"gdåº“ä¸­{'å·²æˆåŠŸåˆ›å»º' if table_exists else 'æœªåˆ›å»º'}ads_product_value_evaluationè¡¨ï¼ŒæˆåŠŸæ’å…¥{count}æ¡æ•°æ®")

spark.stop()